# CLASIFICACION_MALWARE_UIDE_2024

## Grupo 4 - Integrantes
* EDGAR DANIEL SULCA NARANJO
* GABRIELA ESTEFANIA CHILIQUINGA JIMENEZ
* KAREN LISSETTE PLAZA JIMENEZ
* MARJURY LISBETH DIAZ HARO
* JARIS SURYA AIZPRUA BARRIOS

## 1) Introducción

En el contexto actual, la ciberseguridad es un campo crítico con creciente relevancia. Este ejercicio tiene como objetivo construir un clasificador de malware utilizando un dataset personalizado creado específicamente para este propósito.

## 2) Preparación del dataset

* Cargar el dataset: Leeremos el archivo CSV para ver las primeras filas y entender la estructura de los datos.
* Exploración inicial: Identificaremos el número de filas, columnas, tipos de datos de las columnas, y si hay valores nulos.
* Preprocesamiento: Trataremos los valores nulos o inconsistentes.
* Reducción de dimensionalidad: Evaluaremos la necesidad y aplicaremos técnicas de reducción si es necesario.
* División del dataset: Separaremos los datos en conjuntos de entrenamiento, validación y prueba.

### 2.1) Carga del dataset
El dataset contiene 532 columnas, incluyendo una columna de etiquetas (Label) que indica si el archivo ejecutable es malicioso o no ("non-malicious" para benigno) y 531 características numéricas (F_1 a F_531) que representan las características híbridas extraídas de los archivos ejecutables.

### 2.2) Exploración inicial
El dataset consta de 373 filas y 532 columnas. Todos los atributos, excepto la columna de etiquetas (Label), son de tipo numérico (int64), lo que sugiere que las características han sido preprocesadas para representar valores enteros. No se han detectado valores nulos en ninguna de las columnas.

### 2.3) Preprocesamiento
Dado que no hay valores nulos, podemos proceder directamente a evaluar la necesidad de reducción de dimensionalidad antes de dividir el dataset.

### 2.4) Reducción de dimensiones
Se realiza un análisis rápido de la varianza de las características para identificar si hay variables con poca varianza que podrían ser candidatas a eliminarse, lo cual es un paso preliminar antes de considerar técnicas más avanzadas de reducción de dimensionalidad como PCA (Análisis de Componentes Principales).

#### 2.4.1) Normalización de los datos
Antes de aplicar PCA, es crucial normalizar los datos para que cada característica tenga media 0 y varianza 1. Esto es importante porque PCA es sensible a las escalas de las variables. La normalización asegura que las características con varianzas más grandes no dominen los resultados.

#### 2.4.2) Aplicación de PCA
PCA se aplica a los datos normalizados para identificar las direcciones (componentes principales) que maximizan la varianza en los datos. Esto se hace calculando los vectores propios y valores propios de la matriz de covarianza de los datos normalizados o mediante la descomposición en valores singulares (SVD) de la matriz de datos.

#### 2.4.3) Selección de Componentes
Después de aplicar un filtro de varianza con un umbral diseñado para eliminar características con baja varianza (características que juntas explican al menos el 95% de la varianza total), encontramos que solo 64 de las 531 características tienen una varianza no baja. Esto sugiere que una gran parte de las características podrían no contribuir significativamente a la capacidad predictiva del modelo y que la reducción de dimensionalidad podría ser beneficiosa para simplificar el modelo y potencialmente mejorar el rendimiento.
El umbral del 95% en el contexto de PCA (Análisis de Componentes Principales) es una elección comúnmente utilizada pero arbitraria que busca equilibrar la reducción de dimensionalidad con la retención de información.

#### 2.4.4) Transformación de los Datos
Los datos originales se proyectan en el espacio de los 64 componentes principales seleccionados. Esto se realiza multiplicando la matriz de datos original (normalizada) por la matriz de vectores propios correspondientes a los componentes seleccionados. El resultado es un nuevo conjunto de datos de dimensiones reducidas (64 características) que conserva el 95% de la varianza original.

### 2.5) División del dataset
El siguiente paso es dividir el dataset en conjuntos de entrenamiento, validación y prueba. Esta división es crucial para entrenar modelos de machine learning, validar su rendimiento y finalmente probar su capacidad para generalizar a nuevos datos. La división típica es 70% para entrenamiento, 15% para validación, y 15% para prueba, aunque estas proporciones pueden variar según el tamaño y la especificidad del dataset.

## 3) Selección de técnicas de aprendizaje automático

### 3.1) Técnicas de aprendizaje automático para la clasificación de Malware
La clasificación de malware es un problema de clasificación binaria donde el objetivo es distinguir entre software benigno y malicioso. Varias técnicas de aprendizaje automático son adecuadas para esta tarea, incluyendo:

* Árboles de Decisión y Random Forest: Son métodos potentes y fáciles de interpretar que pueden manejar características categóricas y numéricas. Random Forest, en particular, es efectivo en conjuntos de datos de alta dimensionalidad y puede manejar el desbalance de clases mediante el ajuste de pesos de clase o mediante técnicas de muestreo.
* Gradient Boosting Machines (GBM): Técnicas como XGBoost, LightGBM, y CatBoost son muy populares por su eficacia en competiciones de ciencia de datos. Estos métodos construyen modelos de manera secuencial para corregir los errores de los modelos anteriores y pueden manejar el desbalance de clases ajustando los pesos de clase o usando técnicas de muestreo.
* Support Vector Machines (SVM): SVM puede ser muy efectivo para conjuntos de datos de alta dimensionalidad y puede configurarse para manejar el desbalance de clases mediante el ajuste de los parámetros de penalización.
* Redes Neuronales Artificiales: Las redes neuronales profundas pueden capturar complejas relaciones no lineales en los datos. Para el desbalance de clases, se pueden ajustar los pesos de las clases o utilizar técnicas de muestreo para entrenar modelos más equilibrados.

### 3.2) Selección de técnicas y justificación
Para este caso, se recomienda utilizar Random Forest y XGBoost por las siguientes razones:

* Random Forest: Es robusto frente al desbalance de clases y puede manejar una alta dimensionalidad sin la necesidad de una selección extensiva de características. También proporciona una buena interpretabilidad a través de la importancia de las características.
* XGBoost: Es conocido por su rendimiento y eficiencia en problemas de clasificación. XGBoost ofrece formas integradas para manejar el desbalance de clases mediante el ajuste de los parámetros scale_pos_weight y max_delta_step, lo que puede mejorar significativamente el rendimiento en conjuntos de datos desbalanceados.

## 4) Conclusiones

### 4.1) Modelo Random Forest
La evaluación final del modelo Random Forest en el conjunto de prueba proporciona una visión detallada de su rendimiento en la tarea de clasificación, mostrando resultados altamente positivos, aunque no perfectos, lo cual es común y a menudo esperado en aplicaciones del mundo real. Los resultados indican lo siguiente:

* Clase 0 (No Malicioso):
  Precisión: 0.92, lo que indica que el 92% de las instancias clasificadas como no maliciosas eran correctas. Hay un pequeño porcentaje de falsos positivos.
  Recall: 1.00, significando que el modelo identificó correctamente todas las instancias reales de la clase no maliciosa. No hubo falsos negativos para esta clase.
  F1-Score: 0.96, una medida que combina precisión y recall, sugiere un excelente equilibrio para la clase no maliciosa.

* Clase 1 (Malicioso):
  Precisión: 1.00, lo que indica que todas las instancias clasificadas como maliciosas eran correctas. No hubo falsos positivos para esta clase.
  Recall: 0.98, lo que significa que el modelo identificó correctamente el 98% de las instancias maliciosas reales, dejando un 2% de falsos negativos.
  F1-Score: 0.99, refleja una precisión y recall muy altas para la clase maliciosa.

* Accuracy General: 0.98, lo que muestra que el 98% de todas las clasificaciones fueron correctas.

### 4.2) Modelo XGBoost
La evaluación final del modelo XGBoost en el conjunto de prueba revela un rendimiento muy similar al observado con el modelo Random Forest, lo que indica una alta efectividad en la clasificación del malware. Los resultados detallados son los siguientes:

* Clase 0 (No Malicioso):
Precisión: 0.92, lo que indica que el 92% de las predicciones de la clase no maliciosa fueron correctas, sugiriendo la presencia de algunos falsos positivos.
Recall: 1.00, significando que el modelo fue capaz de identificar correctamente todas las instancias reales de la clase no maliciosa, indicando la ausencia de falsos negativos para esta clase.
F1-Score: 0.96, demuestra un equilibrio fuerte entre precisión y recall para la clase no maliciosa.

* Clase 1 (Malicioso):
   Precisión: 1.00, indicando que todas las instancias clasificadas como maliciosas eran correctas, mostrando una ausencia de falsos positivos para esta clase.
   Recall: 0.98, lo que significa que el modelo identificó correctamente el 98% de las instancias maliciosas reales, dejando un pequeño margen de falsos negativos.
   F1-Score: 0.99, refleja un alto rendimiento en la clasificación de malware.

* Accuracy General: 0.98, indica que el 98% de todas las predicciones fueron correctas.

XGBoost ha demostrado ser tan efectivo como Random Forest en este escenario de clasificación de malware, con métricas de evaluación indicando un alto grado de precisión en la identificación de archivos maliciosos y benignos. La elección entre XGBoost y Random Forest podría entonces basarse en otros factores, como la eficiencia computacional, la facilidad de interpretación o la preferencia personal basada en la experiencia de modelado específica. En cualquier caso, ambos modelos representan herramientas valiosas para la detección de malware en este dataset.

### 4.3) AUC-ROC (Área Bajo la Curva - Característica Operativa del Receptor)

* Alto Rendimiento: Ambos modelos han demostrado ser altamente efectivos para la tarea en cuestión. Un AUC-ROC alto sugiere que ambos modelos son capaces de clasificar correctamente las instancias positivas y negativas con una alta confianza.

* Diferencias Mínimas entre Modelos: La ligera diferencia en los valores AUC-ROC entre Random Forest y XGBoost no es significativa para determinar un claro ganador entre ambos. La elección del modelo podría depender de otros factores como la interpretabilidad, el tiempo de entrenamiento, y la facilidad de implementación y mantenimiento.

Los modelos Random Forest y XGBoost han demostrado un excelente rendimiento en la clasificación de malware, con AUC-ROC cercanos a 1. Estos resultados resaltan la efectividad de las técnicas avanzadas de machine learning para tareas de seguridad cibernética. Sin embargo, la elección entre estos modelos debe considerar varios factores, incluyendo la complejidad del modelo, la interpretabilidad, y la facilidad de implementación, así como la necesidad de validación adicional para confirmar la robustez y la generalización del modelo.

## 5) Recomendaciones

* Aunque ambos modelos mostraron un desempeño sobresaliente, es crucial realizar evaluaciones rigurosas, incluyendo validación cruzada y pruebas con conjuntos de datos externos no vistos, para asegurar la generalización de los modelos fuera del conjunto de datos de prueba.
* En presencia de desbalance de clases, explorar técnicas avanzadas de balanceo como SMOTE (Synthetic Minority Over-sampling Technique) o ajustes en los pesos de las clases durante el entrenamiento del modelo puede proporcionar mejoras en el rendimiento, especialmente en la sensibilidad y especificidad para la clase minoritaria.
* Aunque PCA se utilizó para reducir la dimensionalidad, realizar una ingeniería de características adicional, incluyendo la selección de características específicas basadas en el conocimiento del dominio, puede mejorar la relevancia de las características para la tarea de clasificación y, por lo tanto, el rendimiento del modelo.
* Dedicar tiempo a interpretar los modelos y analizar los casos de error puede proporcionar insights valiosos sobre cómo mejorarlos. Herramientas como SHAP (SHapley Additive exPlanations) pueden ayudar a entender la importancia y el impacto de las características individuales en las predicciones del modelo.
* Además de Random Forest y XGBoost, considerar la evaluación de otros modelos de machine learning, incluidas las redes neuronales profundas, que podrían capturar complejidades en los datos que los modelos basados en árboles no pueden.
* Para aplicaciones prácticas, considerar la implementación de modelos en un sistema de detección de malware en tiempo real, asegurándose de incluir mecanismos para el reentrenamiento periódico con nuevos datos y el monitoreo continuo del rendimiento del modelo para adaptarse a las nuevas tendencias de malware.
* La detección efectiva de malware a menudo requiere un enfoque multidisciplinario que combine expertise en ciberseguridad, análisis de datos y machine learning. Colaborar con expertos en seguridad puede proporcionar perspectivas importantes para mejorar la selección de características y la interpretación del modelo.
